<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Week 4: PyTorch Learning Module</title>

    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            color: #333;
            margin: 20px;
        }

        h1 {
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 1em;
        }

        h2 {
            font-size: 2em;
            margin-bottom: 0.8em;
            color: #006747;
        }

        p {
            font-size: 1.2em;
            line-height: 1.6;
            margin-bottom: 1.2em;
        }

        .section {
            margin: 30px auto;
            padding: 20px;
            max-width: 900px;
            background-color: #ffffff;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        a {
            color: #006747;
            text-decoration: none;
            font-weight: bold;
        }

        a:hover {
            text-decoration: underline;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
        }
    </style>
</head><body><div class="container">
<h1>Week 4: PyTorch Learning Module</h1>
<div class="section">
<h2>What We Covered So Far</h2>
<p>In this module, we have explored key concepts in neural network training, including <strong>derivatives</strong>, <strong>autograd,</strong> <strong>gradient descent</strong>, and <strong>loss functions</strong>. These topics focus on how neural networks learn by minimizing errors, computing gradients with autograd, and updating parameters using optimization algorithms like gradient descent. Loss functions measure the model’s performance, guiding these updates.</p>
</div>
<div class="section">
<h2>Module for Deeper Learning</h2>
<p>For a deeper dive into PyTorch’s <strong>autograd</strong> system, which automates the gradient computation during backpropagation, explore the official <a href="https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html" target="_blank" rel="noopener">Autograd Tutorial</a>. This tutorial covers creating tensors with gradient tracking, performing backpropagation, and understanding computational graphs, all essential for training efficient neural networks.</p>
</div>
</div></body></html>