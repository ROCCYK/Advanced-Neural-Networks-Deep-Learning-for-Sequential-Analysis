{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816d7ed7",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch and Tensors\n",
    "PyTorch is a popular deep learning framework that provides efficient tensor computations. \n",
    "Tensors are the fundamental building blocks in PyTorch, similar to NumPy arrays but with added capabilities for GPU acceleration.\n",
    "In this notebook, we will explore various tensor operations in PyTorch, ranging from basic arithmetic to advanced automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "# Simple tensor creation\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870c2fe",
   "metadata": {},
   "source": [
    "## Basic Tensor Operations\n",
    "In this section, we will cover basic arithmetic operations on tensors, such as addition, subtraction, multiplication, and division. \n",
    "PyTorch allows you to perform these operations using built-in functions or Python operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da86612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two tensors\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Addition\n",
    "result_add = a + b\n",
    "print('Addition:', result_add)\n",
    "\n",
    "# Subtraction\n",
    "result_sub = a - b\n",
    "print('Subtraction:', result_sub)\n",
    "\n",
    "# Multiplication\n",
    "result_mul = a * b\n",
    "print('Multiplication:', result_mul)\n",
    "\n",
    "# Division\n",
    "result_div = a / b\n",
    "print('Division:', result_div)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0aae0b",
   "metadata": {},
   "source": [
    "## Tensor Indexing and Slicing\n",
    "Indexing and slicing in tensors are similar to NumPy arrays. You can access elements using indices and extract sub-tensors using slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82402e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D tensor\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Indexing: Access element at row 0, column 1\n",
    "element = tensor_2d[0, 1]\n",
    "print('Element at (0,1):', element)\n",
    "\n",
    "# Slicing: Get the first row\n",
    "row = tensor_2d[0, :]\n",
    "print('First row:', row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f575e49",
   "metadata": {},
   "source": [
    "## Tensor Creation and Initialization\n",
    "PyTorch provides various methods to create tensors, such as zeros, ones, random, and from lists. \n",
    "You can also specify the data type of the tensor during creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c805b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of zeros\n",
    "tensor_zeros = torch.zeros(3, 3)\n",
    "print('Zeros tensor:\\n', tensor_zeros)\n",
    "\n",
    "# Create a tensor of ones\n",
    "tensor_ones = torch.ones(2, 2)\n",
    "print('Ones tensor:\\n', tensor_ones)\n",
    "\n",
    "# Create a random tensor\n",
    "tensor_random = torch.rand(2, 3)\n",
    "print('Random tensor:\\n', tensor_random)\n",
    "\n",
    "# Create a tensor from a list\n",
    "tensor_from_list = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print('Tensor from list:', tensor_from_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6238ed",
   "metadata": {},
   "source": [
    "## Mathematical Operations on Tensors\n",
    "PyTorch supports various mathematical functions, including element-wise operations and reduction operations, such as sum, mean, and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "# Sum of elements\n",
    "sum_tensor = torch.sum(tensor)\n",
    "print('Sum:', sum_tensor)\n",
    "\n",
    "# Mean of elements\n",
    "mean_tensor = torch.mean(tensor)\n",
    "print('Mean:', mean_tensor)\n",
    "\n",
    "# Max of elements\n",
    "max_tensor = torch.max(tensor)\n",
    "print('Max:', max_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a10ee",
   "metadata": {},
   "source": [
    "## Advanced Tensor Operations\n",
    "Advanced operations in PyTorch include matrix multiplication, transposing tensors, finding the inverse of a matrix, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61198cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "result_matmul = torch.matmul(a, b)\n",
    "print('Matrix Multiplication:\\n', result_matmul)\n",
    "\n",
    "# Transpose of a tensor\n",
    "result_transpose = a.T\n",
    "print('Transpose:\\n', result_transpose)\n",
    "\n",
    "# Inverse of a matrix\n",
    "a_float = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "result_inverse = torch.inverse(a_float)\n",
    "print('Inverse:\\n', result_inverse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebf5cd",
   "metadata": {},
   "source": [
    "## GPU Operations with Tensors\n",
    "PyTorch supports GPU acceleration for tensor computations. You can move tensors to a GPU device using the `to()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Create a tensor and move it to GPU\n",
    "    tensor_gpu = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
    "    print('Tensor on GPU:', tensor_gpu)\n",
    "else:\n",
    "    print('CUDA is not available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ff6de",
   "metadata": {},
   "source": [
    "## Tensor Reshaping and Broadcasting\n",
    "Reshaping tensors is often required when preparing data for neural networks. Broadcasting allows operations between tensors of different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape a tensor\n",
    "flat_tensor = torch.rand(8)\n",
    "reshaped_tensor = flat_tensor.reshape(2, 4)\n",
    "print('Reshaped Tensor:\\n', reshaped_tensor)\n",
    "\n",
    "# Broadcasting example\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([[4], [5], [6]])\n",
    "result_broadcast = a + b\n",
    "print('Broadcasting Result:\\n', result_broadcast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b2dcf",
   "metadata": {},
   "source": [
    "## Using Autograd for Automatic Differentiation\n",
    "Autograd in PyTorch provides automatic differentiation for all tensor operations. It is essential for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with requires_grad=True to track computations\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Perform operations\n",
    "y = x * 2\n",
    "z = y.mean()\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "\n",
    "# Gradients\n",
    "print('Gradients:', x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6e080",
   "metadata": {},
   "source": [
    "## Summary and Conclusion\n",
    "In this notebook, we explored a wide range of tensor operations in PyTorch, from basic arithmetic and indexing to advanced operations like GPU acceleration and autograd. \n",
    "Understanding these operations is crucial for effectively working with PyTorch and building deep learning models."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
